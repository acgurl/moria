# å¿«é€Ÿå¼€å§‹æŒ‡å— ğŸš€

æœ¬æŒ‡å—å°†å¸®åŠ©ä½ åœ¨5åˆ†é’Ÿå†…è¿è¡ŒMorié¡¹ç›®ã€‚

## å‰ç½®è¦æ±‚

- Python 3.10+
- uvï¼ˆPythonåŒ…ç®¡ç†å™¨ï¼‰
- ä¸€ä¸ªLLM APIå¯†é’¥ï¼ˆOpenAIã€DeepSeekã€é€šä¹‰åƒé—®ç­‰ï¼‰

## æ­¥éª¤1: å®‰è£…ä¾èµ–

```bash
# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
uv venv

# æ¿€æ´»è™šæ‹Ÿç¯å¢ƒ
# Windows PowerShell:
.venv\Scripts\activate
# Linux/Mac:
source .venv/bin/activate

# å®‰è£…é¡¹ç›®
uv pip install -e .
```

## æ­¥éª¤2: é…ç½®

### æ–¹å¼A: ä½¿ç”¨ç¯å¢ƒå˜é‡ï¼ˆæ¨èï¼‰

```bash
# Windows PowerShell:
$env:OPENAI_API_KEY="your-api-key-here"

# Linux/Mac:
export OPENAI_API_KEY="your-api-key-here"
```

ç„¶åå¤åˆ¶é…ç½®æ–‡ä»¶ï¼š

```bash
# Windows PowerShell:
Copy-Item config\models.yaml.example config\models.yaml
Copy-Item config\agents.yaml.example config\agents.yaml
Copy-Item config\config.yaml.example config\config.yaml

# Linux/Mac:
cp config/models.yaml.example config/models.yaml
cp config/agents.yaml.example config/agents.yaml
cp config/config.yaml.example config/config.yaml
```

### æ–¹å¼B: ç›´æ¥ç¼–è¾‘é…ç½®æ–‡ä»¶

1. å¤åˆ¶é…ç½®æ–‡ä»¶ï¼ˆåŒä¸Šï¼‰
2. ç¼–è¾‘ `config/models.yaml`ï¼Œå°† `${OPENAI_API_KEY}` æ›¿æ¢ä¸ºä½ çš„å®é™…APIå¯†é’¥

```yaml
models:
  - model_name: gpt-4
    model_type: openai
    api_key: sk-your-actual-key-here  # ç›´æ¥å¡«å…¥å¯†é’¥
    generate_kwargs:
      temperature: 0.7
      max_tokens: 2000
```

## æ­¥éª¤3: è¿è¡Œ

```bash
python gui/app.py
```

ç„¶ååœ¨æµè§ˆå™¨ä¸­è®¿é—®: http://localhost:7860

## ä½¿ç”¨å…¶ä»–æ¨¡å‹

### DeepSeek

```yaml
# config/models.yaml
models:
  - model_name: deepseek-chat
    model_type: openai
    api_key: ${DEEPSEEK_API_KEY}
    base_url: https://api.deepseek.com/v1
    generate_kwargs:
      temperature: 0.7
```

```yaml
# config/agents.yaml
agents:
  - name: mori
    model: deepseek-chat  # ä½¿ç”¨DeepSeek
    template: mori  # ä½¿ç”¨ç®€çŸ­åç§°
    parallel_tool_calls: true
```

### é€šä¹‰åƒé—®ï¼ˆDashScopeï¼‰

```yaml
# config/models.yaml
models:
  - model_name: qwen-max
    model_type: dashscope
    api_key: ${DASHSCOPE_API_KEY}
    generate_kwargs:
      temperature: 0.7
```

```yaml
# config/agents.yaml
agents:
  - name: mori
    model: qwen-max  # ä½¿ç”¨é€šä¹‰åƒé—®
    template: mori  # ä½¿ç”¨ç®€çŸ­åç§°
    parallel_tool_calls: true
```

### Ollamaï¼ˆæœ¬åœ°æ¨¡å‹ï¼‰

```yaml
# config/models.yaml
models:
  - model_name: llama3
    model_type: ollama
    base_url: http://localhost:11434
    generate_kwargs:
      temperature: 0.8
```

```yaml
# config/agents.yaml
agents:
  - name: mori
    model: llama3  # ä½¿ç”¨æœ¬åœ°Ollamaæ¨¡å‹
    template: mori  # ä½¿ç”¨ç®€çŸ­åç§°
    parallel_tool_calls: false  # Ollamaå¯èƒ½ä¸æ”¯æŒå¹¶è¡Œå·¥å…·è°ƒç”¨
```

## å¸¸è§é—®é¢˜

### Q: å¯åŠ¨æ—¶æç¤ºæ‰¾ä¸åˆ°é…ç½®æ–‡ä»¶

A: ç¡®ä¿ä½ å·²ç»å¤åˆ¶äº†é…ç½®æ–‡ä»¶ç¤ºä¾‹ï¼š
```bash
cp config/models.yaml.example config/models.yaml
cp config/agents.yaml.example config/agents.yaml
cp config/config.yaml.example config/config.yaml
```

### Q: APIå¯†é’¥é”™è¯¯

A: æ£€æŸ¥ä»¥ä¸‹å‡ ç‚¹ï¼š
1. ç¯å¢ƒå˜é‡æ˜¯å¦æ­£ç¡®è®¾ç½®
2. é…ç½®æ–‡ä»¶ä¸­çš„APIå¯†é’¥æ˜¯å¦æ­£ç¡®
3. å¦‚æœä½¿ç”¨ç¯å¢ƒå˜é‡ï¼Œç¡®ä¿æ ¼å¼ä¸º `${ENV_VAR_NAME}`

### Q: ç«¯å£è¢«å ç”¨

A: ä¿®æ”¹ `config/config.yaml` ä¸­çš„ç«¯å£ï¼š
```yaml
server:
  port: 8080  # æ”¹ä¸ºå…¶ä»–ç«¯å£
```

### Q: æ¨¡å‹å“åº”å¾ˆæ…¢

A: å¯ä»¥å°è¯•ï¼š
1. ä½¿ç”¨æ›´å¿«çš„æ¨¡å‹ï¼ˆå¦‚gpt-3.5-turboï¼‰
2. å‡å°‘ `max_tokens` å‚æ•°
3. ä½¿ç”¨æœ¬åœ°Ollamaæ¨¡å‹

## ä¸‹ä¸€æ­¥

- æŸ¥çœ‹ [README.md](README.md) äº†è§£æ›´å¤šåŠŸèƒ½
- æŸ¥çœ‹ [ARCHITECTURE.md](ARCHITECTURE.md) äº†è§£æ¶æ„è®¾è®¡
- è‡ªå®šä¹‰æç¤ºè¯æ¨¡æ¿ï¼šç¼–è¾‘ `mori/template/internal_template/mori.jinja2`
- æ·»åŠ è‡ªå®šä¹‰å·¥å…·ï¼šåœ¨ `mori/tool/internal_tools/` ä¸­æ·»åŠ æ–°å·¥å…·

## è·å–å¸®åŠ©

å¦‚æœ‰é—®é¢˜ï¼Œè¯·æŸ¥çœ‹ï¼š
- [README.md](README.md) - å®Œæ•´æ–‡æ¡£
- [ARCHITECTURE.md](ARCHITECTURE.md) - æ¶æ„è¯´æ˜
- GitHub Issues - æäº¤é—®é¢˜

ç¥ä½ ä½¿ç”¨æ„‰å¿«ï¼ğŸ’•
